### another openvino runtime, with an accelerator profile associated
---
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: ovms-gpu-acc-profile-test
  annotations:
    openshift.io/display-name: OpenVINO Model Server (Supports GPUs - Intel FLEX recommended)
    opendatahub.io/recommended-accelerators: '["intel.com/flex"]'
  labels:
    opendatahub.io/dashboard: "true"
spec:
  builtInAdapter:
    env:
      - name: OVMS_FORCE_TARGET_DEVICE
        value: NVIDIA
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
    runtimeManagementPort: 8888
    serverType: ovms
  containers:
    - args:
        - --port=8001
        - --rest_port=8888
        - --config_path=/models/model_config_list.json
        - --file_system_poll_wait_seconds=0
        - --grpc_bind_address=127.0.0.1
        - --rest_bind_address=127.0.0.1
      image: quay.io/opendatahub/openvino_model_server@sha256:20dbfbaf53d1afbd47c612d953984238cb0e207972ed544a5ea662c2404f276d
      name: ovms
      resources:
        limits:
          cpu: "1"
          memory: 4Gi
        requests:
          cpu: "1"
          memory: 4Gi
  grpcDataEndpoint: port:8001
  grpcEndpoint: port:8085
  multiModel: true
  protocolVersions:
    - grpc-v1
  replicas: 1
  supportedModelFormats:
    - autoSelect: true
      name: openvino_ir
      version: opset1
    - autoSelect: true
      name: onnx
      version: "1"
    - autoSelect: true
      name: tensorflow
      version: "2"
